require('dotenv').config();
const { connectDB, disconnectDB, mongoose } = require('./config/database');
const { getDataFiles, readJsonFile, processFileData, getFileSize } = require('./utils/fileProcessor');

/**
 * Upload data with progress tracking
 */
async function uploadData() {
  console.log('ðŸš€ Starting Patel Full Collection data upload to MongoDB Atlas...\n');

  try {
    // Connect to MongoDB Atlas
    await connectDB();

    // Get all data files
    const files = await getDataFiles();
    console.log(`ðŸ“ Found ${files.length} files to upload:\n`);

    for (const file of files) {
      console.log(`ðŸ“„ Processing: ${file.filename}`);

      try {
        // Get file size for progress indication
        const fileSize = await getFileSize(file.filepath);
        console.log(`   ðŸ“ Size: ${Math.round(fileSize / 1024 / 1024)} MB`);

        // Read and parse JSON file
        const rawData = await readJsonFile(file.filepath);
        console.log(`   ðŸ“Š Records: ${rawData.length}`);

        if (rawData.length === 0) {
          console.log(`   âš ï¸  Skipping empty file\n`);
          continue;
        }

        // Process data for MongoDB insertion
        const processedData = processFileData(rawData, file.collectionName);
        console.log(`   ðŸ”„ Processed records: ${processedData.length}`);

        // Get the collection
        const collection = mongoose.connection.db.collection(file.collectionName);

        // Clear existing data (optional - can be controlled via env var)
        if (process.env.CLEAR_BEFORE_UPLOAD === 'true') {
          await collection.deleteMany({});
          console.log(`   ðŸ—‘ï¸  Cleared existing data`);
        }

        // Insert data in batches for large files
        const batchSize = fileSize > 50 * 1024 * 1024 ? 1000 : 5000; // Smaller batches for large files
        let insertedCount = 0;

        if (processedData.length <= batchSize) {
          // Insert all at once for small files
          const result = await collection.insertMany(processedData, { ordered: false });
          insertedCount = result.insertedCount;
        } else {
          // Batch insert for large files
          for (let i = 0; i < processedData.length; i += batchSize) {
            const batch = processedData.slice(i, i + batchSize);
            const result = await collection.insertMany(batch, { ordered: false });
            insertedCount += result.insertedCount;

            const progress = Math.round((i + batch.length) / processedData.length * 100);
            console.log(`   â³ Progress: ${progress}% (${insertedCount}/${processedData.length})`);
          }
        }

        console.log(`   âœ… Successfully uploaded ${insertedCount} records to ${file.collectionName}\n`);

      } catch (error) {
        console.error(`   âŒ Error uploading ${file.filename}:`, error.message);
        console.log(`   ðŸ’¥ Skipping this file and continuing...\n`);
      }
    }

    console.log('ðŸŽ‰ Upload completed!');
    console.log('\nðŸ“‹ Summary:');
    console.log(`   âœ… Successfully processed ${files.length} files`);
    console.log('   ðŸ”— Data uploaded to: Patel_Test_v2 database');
    console.log('   ðŸŒ MongoDB Atlas connection established');

  } catch (error) {
    console.error('ðŸ’¥ Fatal error during upload:', error.message);
    process.exit(1);
  } finally {
    await disconnectDB();
  }
}

/**
 * Clear database before upload (optional script)
 */
async function clearDatabase() {
  console.log('ðŸ—‘ï¸  Clearing all collections in Patel_Test_v2 database...');

  try {
    await connectDB();

    const collections = [
      'addressbooks',
      'bannermasters',
      'categorymasters',
      'deliveryslots',
      'departmentmasters',
      'favoritemasters',
      'paymentmodes',
      'paymentstatuses',
      'pincodemasters',
      'pincodestoremasters',
      'productmasters',
      'subcategorymasters'
    ];

    for (const collectionName of collections) {
      const collection = mongoose.connection.db.collection(collectionName);
      const result = await collection.deleteMany({});
      console.log(`   ðŸ—‘ï¸  Cleared ${collectionName}: ${result.deletedCount} records`);
    }

    console.log('âœ… Database cleared successfully');

  } catch (error) {
    console.error('âŒ Error clearing database:', error.message);
  } finally {
    await disconnectDB();
  }
}

// Main execution
if (require.main === module) {
  const command = process.argv[2];

  if (command === 'clear') {
    clearDatabase();
  } else {
    uploadData();
  }
}

module.exports = { uploadData, clearDatabase };
